{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code we are using Mixtral with LORA on A100 gpu. I was still not abe to train the mdoel due to memory contraints. However this code showcases my understand and implementation of quantized model along with LORA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q bitsandbytes accelerate transformers peft datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./test_venv/lib/python3.11/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in ./test_venv/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./test_venv/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./test_venv/lib/python3.11/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./test_venv/lib/python3.11/site-packages (from torch) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in ./test_venv/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./test_venv/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./test_venv/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./test_venv/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./test_venv/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./test_venv/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./test_venv/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./test_venv/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./test_venv/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./test_venv/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./test_venv/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./test_venv/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./test_venv/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./test_venv/lib/python3.11/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./test_venv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./test_venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./test_venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_MODEL = \"mistralai/Mistral-7B-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACE_TOKEN'] = "HuggingFace-api-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./test_venv/lib/python3.11/site-packages (3.0.1)\n",
      "Requirement already satisfied: filelock in ./test_venv/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./test_venv/lib/python3.11/site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./test_venv/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./test_venv/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./test_venv/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./test_venv/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./test_venv/lib/python3.11/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in ./test_venv/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in ./test_venv/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in ./test_venv/lib/python3.11/site-packages (from datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in ./test_venv/lib/python3.11/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in ./test_venv/lib/python3.11/site-packages (from datasets) (0.25.2)\n",
      "Requirement already satisfied: packaging in ./test_venv/lib/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./test_venv/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./test_venv/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./test_venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./test_venv/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./test_venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./test_venv/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./test_venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.15.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./test_venv/lib/python3.11/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./test_venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./test_venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./test_venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./test_venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./test_venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./test_venv/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./test_venv/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./test_venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./test_venv/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/kumararn/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "#Load the dataset from Hugging Face\n",
    "dataset = load_dataset(\"zqz979/meta-review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train'].to_pandas()\n",
    "validation = dataset['validation'].to_pandas()\n",
    "test = dataset['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Input  \\\n",
      "0  In this paper, the author investigates how to ...   \n",
      "1  **Summary of contributions:** This paper propo...   \n",
      "2  This paper addresses the problem of MoE routin...   \n",
      "3  This paper discusses applications of variants ...   \n",
      "4  The authors introduce the problem of telegraph...   \n",
      "\n",
      "                                              Output  \n",
      "0  This paper studies how to learn dexterous mani...  \n",
      "1  This paper proposed a new family of losses for...  \n",
      "2  Mixture-of-Expert (MoE) models have demonstrat...  \n",
      "3  In this work, the authors conduct experiments ...  \n",
      "4  This paper presents methods for telegraphic su...  \n",
      "                                               Input  \\\n",
      "0  This paper presents an approach, called EstiNe...   \n",
      "1  The paper aimed at improving the performance o...   \n",
      "2  The submission shows the numerical instabiliti...   \n",
      "3  This paper presents a method for training a ne...   \n",
      "4  This paper proposes a new task of Video Text V...   \n",
      "\n",
      "                                              Output  \n",
      "0  The paper focuses on hybrid pipelines that con...  \n",
      "1  This paper addresses the problem of recommenda...  \n",
      "2  The paper studies the instabilities of neural ...  \n",
      "3  This paper proposes a method for training stoc...  \n",
      "4  The paper presents a new video text VQA datase...  \n",
      "                                               Input  \\\n",
      "0   This paper presents a bert-gat-crf framework ...   \n",
      "1  The authors extend the out-of-distribution (OO...   \n",
      "2  This paper tries to give a measurement method ...   \n",
      "3  This paper proposes a new gradient attack meth...   \n",
      "4  This work proposed to evaluate the robustness ...   \n",
      "\n",
      "                                              Output  \n",
      "0  The paper present results using syntactic info...  \n",
      "1  The authors focus on large scale out-of-distri...  \n",
      "2  The problem studied in this paper is interesti...  \n",
      "3  The major criticism of this paper after the in...  \n",
      "4  This paper proposes a novel challenge setting:...  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and convert to Pandas DataFrames, resetting the index immediately\n",
    "train = dataset['train'].to_pandas().reset_index(drop=True)\n",
    "validation = dataset['validation'].to_pandas().reset_index(drop=True)\n",
    "test = dataset['test'].to_pandas().reset_index(drop=True)\n",
    "\n",
    "# Now the DataFrames will no longer have an index column, so you won’t encounter it later during tokenization or conversion\n",
    "\n",
    "# Preview the dataset structure after resetting the index\n",
    "print(train.head())\n",
    "print(validation.head())\n",
    "print(test.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home1/kumararn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Download stop words from nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def is_latex_symbol(token):\n",
    "    \"\"\"Improved LaTeX symbol check for mathematical symbols.\"\"\"\n",
    "    latex_pattern = r\"\\\\[a-zA-Z]+|[{}^]\"\n",
    "    return re.match(latex_pattern, token) is not None\n",
    "\n",
    "# Preprocessing function tailored for your dataset\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocesses the input/output text while preserving LaTeX symbols.\"\"\"\n",
    "    \n",
    "    # Step 1: Lowercase the text\n",
    "    text = text.lower() if text else \"\"\n",
    "    \n",
    "    # Step 2: Tokenize the text\n",
    "    tokens = text.split()  # Tokenizing the text\n",
    "    \n",
    "    # Step 3: Remove stop words (except for LaTeX symbols)\n",
    "    processed_tokens = []\n",
    "    for token in tokens:\n",
    "        if is_latex_symbol(token):  # Keep LaTeX symbols intact\n",
    "            processed_tokens.append(token)\n",
    "        elif token not in stop_words:  # Remove stop words only from the general text\n",
    "            processed_tokens.append(token)\n",
    "    \n",
    "    # Step 4: Remove special characters from general text, but preserve LaTeX symbols\n",
    "    processed_tokens = [re.sub(r'[^\\w\\\\{}]', '', token) for token in processed_tokens]\n",
    "    \n",
    "    # Step 5: Normalize spaces and join tokens back into a single string\n",
    "    processed_text = ' '.join(processed_tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_26319738/ipykernel_6210/214758001.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_cleaned.loc[:, 'input_tokenized'] = train_cleaned['Input'].apply(preprocess_text)\n",
      "/tmp/SLURM_26319738/ipykernel_6210/214758001.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_cleaned.loc[:, 'output_tokenized'] = train_cleaned['Output'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing step\n",
    "train_cleaned = train.dropna(subset=['Input', 'Output'])\n",
    "train_cleaned.loc[:, 'input_tokenized'] = train_cleaned['Input'].apply(preprocess_text)\n",
    "train_cleaned.loc[:, 'output_tokenized'] = train_cleaned['Output'].apply(preprocess_text)\n",
    "\n",
    "# Remove rows where input or output tokenized becomes empty\n",
    "train_cleaned = train_cleaned[train_cleaned['input_tokenized'].str.strip() != '']\n",
    "train_cleaned = train_cleaned[train_cleaned['output_tokenized'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_26319738/ipykernel_6210/3457451400.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_cleaned.loc[:, 'input_tokenized'] = validation_cleaned['Input'].apply(preprocess_text)\n",
      "/tmp/SLURM_26319738/ipykernel_6210/3457451400.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_cleaned.loc[:, 'output_tokenized'] = validation_cleaned['Output'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing step\n",
    "validation_cleaned = validation.dropna(subset=['Input', 'Output'])\n",
    "validation_cleaned.loc[:, 'input_tokenized'] = validation_cleaned['Input'].apply(preprocess_text)\n",
    "validation_cleaned.loc[:, 'output_tokenized'] = validation_cleaned['Output'].apply(preprocess_text)\n",
    "\n",
    "# Remove rows where input or output tokenized becomes empty\n",
    "validation_cleaned = validation_cleaned[validation_cleaned['input_tokenized'].str.strip() != '']\n",
    "validation_cleaned = validation_cleaned[validation_cleaned['output_tokenized'].str.strip() != '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_26319738/ipykernel_6210/78816890.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_cleaned.loc[:, 'input_tokenized'] = test_cleaned['Input'].apply(preprocess_text)\n",
      "/tmp/SLURM_26319738/ipykernel_6210/78816890.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_cleaned.loc[:, 'output_tokenized'] = test_cleaned['Output'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing step\n",
    "test_cleaned = test.dropna(subset=['Input', 'Output'])\n",
    "test_cleaned.loc[:, 'input_tokenized'] = test_cleaned['Input'].apply(preprocess_text)\n",
    "test_cleaned.loc[:, 'output_tokenized'] = test_cleaned['Output'].apply(preprocess_text)\n",
    "\n",
    "# Remove rows where input or output tokenized becomes empty\n",
    "test_cleaned = test_cleaned[test_cleaned['input_tokenized'].str.strip() != '']\n",
    "test_cleaned = test_cleaned[test_cleaned['output_tokenized'].str.strip() != '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/kumararn/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:796: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home1/kumararn/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4109: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home1/kumararn/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4109: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home1/kumararn/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4109: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TARGET_MODEL,use_auth_token=os.getenv('HUGGINGFACE_TOKEN'))\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Function to tokenize input and output\n",
    "def tokenize_function(row):\n",
    "    # Tokenize both input (meta-review) and output (summary)\n",
    "    model_inputs = tokenizer(row['input_tokenized'], max_length=512, truncation=True, padding='max_length')\n",
    "    \n",
    "    # Tokenize output/labels (the summary)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(row['output_tokenized'], max_length=150, truncation=True, padding='max_length')\n",
    "    \n",
    "    # Return only required fields for training\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return {\n",
    "        'input_ids': model_inputs['input_ids'],\n",
    "        'attention_mask': model_inputs['attention_mask'],\n",
    "        'labels': model_inputs['labels']\n",
    "    }\n",
    "\n",
    "# Apply tokenization\n",
    "train_tokenized = train_cleaned.apply(tokenize_function, axis=1, result_type='expand')\n",
    "validation_tokenized = validation_cleaned.apply(tokenize_function, axis=1, result_type='expand')\n",
    "test_tokenized = test_cleaned.apply(tokenize_function, axis=1, result_type='expand')\n",
    "\n",
    "# Drop any unnecessary columns before converting to Hugging Face Dataset\n",
    "train_tokenized = train_tokenized.drop(columns=['__index_level_0__'], errors='ignore')\n",
    "validation_tokenized = validation_tokenized.drop(columns=['__index_level_0__'], errors='ignore')\n",
    "test_tokenized = test_tokenized.drop(columns=['__index_level_0__'], errors='ignore')\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_tokenized.reset_index(drop=True))\n",
    "validation_dataset = Dataset.from_pandas(validation_tokenized.reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_tokenized.reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model with 4bit bnb\n",
    "\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType # type: ignore\n",
    "from transformers import BitsAndBytesConfig, LlamaForCausalLM\n",
    "import torch\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=2,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"v_proj\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/kumararn/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/modeling_utils.py:3274: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "You are using a model of type mistral to instantiate a model of type llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [03:17<00:00, 98.59s/it] \n"
     ]
    }
   ],
   "source": [
    "base_model = LlamaForCausalLM.from_pretrained(\n",
    "    TARGET_MODEL,\n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    use_auth_token=os.getenv('HUGGINGFACE_TOKEN')\n",
    "    )\n",
    "base_model.config.pretraining_tp = 1 # 1 is 7b\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(base_model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 851,968 || all params: 7,242,584,064 || trainable%: 0.0118\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight: False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.0.input_layernorm.weight: False\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.1.input_layernorm.weight: False\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.2.input_layernorm.weight: False\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.3.input_layernorm.weight: False\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.4.input_layernorm.weight: False\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.5.input_layernorm.weight: False\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.6.input_layernorm.weight: False\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.7.input_layernorm.weight: False\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.8.input_layernorm.weight: False\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.9.input_layernorm.weight: False\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.10.input_layernorm.weight: False\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.11.input_layernorm.weight: False\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.12.input_layernorm.weight: False\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.13.input_layernorm.weight: False\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.14.input_layernorm.weight: False\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.15.input_layernorm.weight: False\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.16.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.16.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.16.input_layernorm.weight: False\n",
      "base_model.model.model.layers.16.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.17.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.17.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.17.input_layernorm.weight: False\n",
      "base_model.model.model.layers.17.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.18.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.18.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.18.input_layernorm.weight: False\n",
      "base_model.model.model.layers.18.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.19.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.19.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.19.input_layernorm.weight: False\n",
      "base_model.model.model.layers.19.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.20.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.20.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.20.input_layernorm.weight: False\n",
      "base_model.model.model.layers.20.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.21.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.21.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.21.input_layernorm.weight: False\n",
      "base_model.model.model.layers.21.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.22.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.22.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.22.input_layernorm.weight: False\n",
      "base_model.model.model.layers.22.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.23.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.23.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.23.input_layernorm.weight: False\n",
      "base_model.model.model.layers.23.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.24.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.24.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.24.input_layernorm.weight: False\n",
      "base_model.model.model.layers.24.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.25.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.25.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.25.input_layernorm.weight: False\n",
      "base_model.model.model.layers.25.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.26.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.26.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.26.input_layernorm.weight: False\n",
      "base_model.model.model.layers.26.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.27.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.27.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.27.input_layernorm.weight: False\n",
      "base_model.model.model.layers.27.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.28.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.28.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.28.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.28.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.28.input_layernorm.weight: False\n",
      "base_model.model.model.layers.28.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.29.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.29.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.29.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.29.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.29.input_layernorm.weight: False\n",
      "base_model.model.model.layers.29.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.30.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.30.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.30.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.30.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.30.input_layernorm.weight: False\n",
      "base_model.model.model.layers.30.post_attention_layernorm.weight: False\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.31.self_attn.k_proj.weight: False\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight: False\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight: True\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight: True\n",
      "base_model.model.model.layers.31.self_attn.o_proj.weight: False\n",
      "base_model.model.model.layers.31.mlp.gate_proj.weight: False\n",
      "base_model.model.model.layers.31.mlp.up_proj.weight: False\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight: False\n",
      "base_model.model.model.layers.31.input_layernorm.weight: False\n",
      "base_model.model.model.layers.31.post_attention_layernorm.weight: False\n",
      "base_model.model.model.norm.weight: False\n",
      "base_model.model.lm_head.weight: False\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): LlamaForCausalLM(\n",
      "      (model): LlamaModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x LlamaDecoderLayer(\n",
      "            (self_attn): LlamaSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=2, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=2, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=2, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=2, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (rotary_emb): LlamaRotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:23:00.940692Z",
     "iopub.status.busy": "2024-10-13T12:23:00.940285Z",
     "iopub.status.idle": "2024-10-13T12:23:12.352673Z",
     "shell.execute_reply": "2024-10-13T12:23:12.351659Z",
     "shell.execute_reply.started": "2024-10-13T12:23:00.940650Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm=False,  # For causal language modeling, set `mlm=False`\n",
    "    pad_to_multiple_of=8  # This helps with aligning tensor sizes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./test_venv/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./test_venv/lib/python3.11/site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./test_venv/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./test_venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./test_venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:23:12.354653Z",
     "iopub.status.busy": "2024-10-13T12:23:12.354009Z",
     "iopub.status.idle": "2024-10-13T12:23:12.360506Z",
     "shell.execute_reply": "2024-10-13T12:23:12.359441Z",
     "shell.execute_reply.started": "2024-10-13T12:23:12.354613Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy_val = accuracy_score(labels, predictions)\n",
    "    roc_auc_val = roc_auc_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_val,\n",
    "        \"roc_auc\": roc_auc_val,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:23:12.362129Z",
     "iopub.status.busy": "2024-10-13T12:23:12.361761Z",
     "iopub.status.idle": "2024-10-13T12:23:12.382214Z",
     "shell.execute_reply": "2024-10-13T12:23:12.381422Z",
     "shell.execute_reply.started": "2024-10-13T12:23:12.362081Z"
    }
   },
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:23:12.383546Z",
     "iopub.status.busy": "2024-10-13T12:23:12.383220Z",
     "iopub.status.idle": "2024-10-13T12:23:12.389667Z",
     "shell.execute_reply": "2024-10-13T12:23:12.388879Z",
     "shell.execute_reply.started": "2024-10-13T12:23:12.383513Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "OUTPUT_DIR = Path(\"./\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:23:12.391284Z",
     "iopub.status.busy": "2024-10-13T12:23:12.390788Z",
     "iopub.status.idle": "2024-10-13T12:23:26.524224Z",
     "shell.execute_reply": "2024-10-13T12:23:26.523022Z",
     "shell.execute_reply.started": "2024-10-13T12:23:12.391250Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trl in ./test_venv/lib/python3.11/site-packages (0.11.3)\n",
      "Requirement already satisfied: torch>=1.4.0 in ./test_venv/lib/python3.11/site-packages (from trl) (2.4.1)\n",
      "Requirement already satisfied: transformers>=4.40.0 in ./test_venv/lib/python3.11/site-packages (from trl) (4.45.2)\n",
      "Requirement already satisfied: accelerate in ./test_venv/lib/python3.11/site-packages (from trl) (1.0.1)\n",
      "Requirement already satisfied: datasets in ./test_venv/lib/python3.11/site-packages (from trl) (3.0.1)\n",
      "Requirement already satisfied: tyro>=0.5.11 in ./test_venv/lib/python3.11/site-packages (from trl) (0.8.12)\n",
      "Requirement already satisfied: numpy>=1.18.2 in ./test_venv/lib/python3.11/site-packages (from trl) (2.1.2)\n",
      "Requirement already satisfied: filelock in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./test_venv/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./test_venv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./test_venv/lib/python3.11/site-packages (from transformers>=4.40.0->trl) (0.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./test_venv/lib/python3.11/site-packages (from transformers>=4.40.0->trl) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./test_venv/lib/python3.11/site-packages (from transformers>=4.40.0->trl) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./test_venv/lib/python3.11/site-packages (from transformers>=4.40.0->trl) (2024.9.11)\n",
      "Requirement already satisfied: requests in ./test_venv/lib/python3.11/site-packages (from transformers>=4.40.0->trl) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./test_venv/lib/python3.11/site-packages (from transformers>=4.40.0->trl) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./test_venv/lib/python3.11/site-packages (from transformers>=4.40.0->trl) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./test_venv/lib/python3.11/site-packages (from transformers>=4.40.0->trl) (4.66.5)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in ./test_venv/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in ./test_venv/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (13.9.2)\n",
      "Requirement already satisfied: shtab>=1.5.6 in ./test_venv/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: psutil in ./test_venv/lib/python3.11/site-packages (from accelerate->trl) (6.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./test_venv/lib/python3.11/site-packages (from datasets->trl) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./test_venv/lib/python3.11/site-packages (from datasets->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./test_venv/lib/python3.11/site-packages (from datasets->trl) (2.2.3)\n",
      "Requirement already satisfied: xxhash in ./test_venv/lib/python3.11/site-packages (from datasets->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in ./test_venv/lib/python3.11/site-packages (from datasets->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in ./test_venv/lib/python3.11/site-packages (from datasets->trl) (3.10.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./test_venv/lib/python3.11/site-packages (from aiohttp->datasets->trl) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./test_venv/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./test_venv/lib/python3.11/site-packages (from aiohttp->datasets->trl) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./test_venv/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./test_venv/lib/python3.11/site-packages (from aiohttp->datasets->trl) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./test_venv/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./test_venv/lib/python3.11/site-packages (from requests->transformers>=4.40.0->trl) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./test_venv/lib/python3.11/site-packages (from requests->transformers>=4.40.0->trl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./test_venv/lib/python3.11/site-packages (from requests->transformers>=4.40.0->trl) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./test_venv/lib/python3.11/site-packages (from requests->transformers>=4.40.0->trl) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./test_venv/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./test_venv/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./test_venv/lib/python3.11/site-packages (from jinja2->torch>=1.4.0->trl) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./test_venv/lib/python3.11/site-packages (from pandas->datasets->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./test_venv/lib/python3.11/site-packages (from pandas->datasets->trl) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./test_venv/lib/python3.11/site-packages (from pandas->datasets->trl) (2024.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./test_venv/lib/python3.11/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./test_venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./test_venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./test_venv/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->trl) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:23:26.526411Z",
     "iopub.status.busy": "2024-10-13T12:23:26.525992Z",
     "iopub.status.idle": "2024-10-13T12:23:26.978688Z",
     "shell.execute_reply": "2024-10-13T12:23:26.977675Z",
     "shell.execute_reply.started": "2024-10-13T12:23:26.526363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:23:26.984726Z",
     "iopub.status.busy": "2024-10-13T12:23:26.984363Z",
     "iopub.status.idle": "2024-10-13T12:23:26.989645Z",
     "shell.execute_reply": "2024-10-13T12:23:26.988769Z",
     "shell.execute_reply.started": "2024-10-13T12:23:26.984690Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:23:26.991108Z",
     "iopub.status.busy": "2024-10-13T12:23:26.990780Z",
     "iopub.status.idle": "2024-10-13T12:30:23.789785Z",
     "shell.execute_reply": "2024-10-13T12:30:23.788217Z",
     "shell.execute_reply.started": "2024-10-13T12:23:26.991074Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/kumararn/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "  0%|          | 0/480 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  4%|▍         | 20/480 [01:18<25:21,  3.31s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4989, 'grad_norm': 3.31453537940979, 'learning_rate': 5e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 11.78 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.68 GiB is free. Including non-PyTorch memory, this process has 27.88 GiB memory in use. Of the allocated memory 15.65 GiB is allocated by PyTorch, and 11.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 40\u001b[0m\n\u001b[1;32m      6\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      7\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39mOUTPUT_DIR,\n\u001b[1;32m      8\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#     device_map= 'auto'# if DEBUG else 'wandb',\u001b[39;00m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer( \n\u001b[1;32m     30\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     31\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/trainer.py:2467\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2467\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/trainer.py:2915\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2913\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2915\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2918\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n",
      "File \u001b[0;32m~/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/trainer.py:2872\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2872\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2873\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2875\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/trainer.py:3868\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3865\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3867\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3868\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3869\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3871\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3872\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3878\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/trainer.py:4086\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4084\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((logits))\n\u001b[1;32m   4085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_eval_metrics \u001b[38;5;129;01mor\u001b[39;00m description \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 4086\u001b[0m         \u001b[43mall_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4088\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((labels))\n",
      "File \u001b[0;32m~/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:322\u001b[0m, in \u001b[0;36mEvalLoopContainer.add\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_nested_concat \u001b[38;5;28;01melse\u001b[39;00m [tensors]\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_nested_concat:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mappend(tensors)\n",
      "File \u001b[0;32m~/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:136\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, Mapping):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n\u001b[1;32m    139\u001b[0m         {k: nested_concat(t, new_tensors[k], padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    140\u001b[0m     )\n",
      "File \u001b[0;32m~/ondemand/data/sys/research/test/test_venv/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:94\u001b[0m, in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     91\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m atleast_1d(tensor2)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n\u001b[1;32m     97\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m (tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 11.78 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.68 GiB is free. Including non-PyTorch memory, this process has 27.88 GiB memory in use. Of the allocated memory 15.65 GiB is allocated by PyTorch, and 11.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "# from trl import SFTTrainer\n",
    "\n",
    "steps = 5 if DEBUG else 20\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    max_grad_norm=0.3,\n",
    "    optim='paged_adamw_32bit',\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    warmup_steps=steps,\n",
    "    eval_steps=steps,\n",
    "    logging_steps=steps,\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=2,\n",
    "#     device_map= 'auto'# if DEBUG else 'wandb',\n",
    ")\n",
    "\n",
    "trainer = Trainer( \n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "  \n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we ran out of memory during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3.12.2 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
